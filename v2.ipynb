{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40310b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ container_ocr_v2/main.py\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import re\n",
    "from utils import crop_image_with_box, draw_box_and_label\n",
    "from preprocessing import clean_ocr_image\n",
    "\n",
    "# --- CONFIG ---\n",
    "MODEL_PATH = \"/Users/tenaity/Documents/MSE/asignment/yolo_runs/container-code-detector-v1/weights/best.pt\"\n",
    "IMAGE_PATH = \"/Users/tenaity/Documents/MSE/asignment/test.jpg\"\n",
    "DEVICE = \"mps\"  # For Macbook M1/M2\n",
    "\n",
    "# --- INITIALIZE ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# --- OCR LOGIC ---\n",
    "def extract_text(img):\n",
    "    config = r\"--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789./\\n\"\n",
    "    text = pytesseract.image_to_string(img, config=config)\n",
    "    return text\n",
    "\n",
    "def extract_fields(text):\n",
    "    container_code = re.findall(r\"[A-Z]{4}\\s?\\d{6}\\s?\\d\", text.upper())\n",
    "    tare_weight = re.findall(r\"TARE[^\\d]*(\\d+[\\.,]?\\d*)\\s*(KGS|KG)?\", text.upper())\n",
    "    gross_weight = re.findall(r\"GROSS[^\\d]*(\\d+[\\.,]?\\d*)\\s*(KGS|KG)?\", text.upper())\n",
    "    return {\n",
    "        \"container_code\": container_code[0] if container_code else \"\",\n",
    "        \"tare_weight\": tare_weight[0][0] if tare_weight else \"\",\n",
    "        \"gross_weight\": gross_weight[0][0] if gross_weight else \"\"\n",
    "    }\n",
    "\n",
    "# --- PROCESS ---\n",
    "results = []\n",
    "for fname in os.listdir(IMAGE_PATH):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(IMAGE_PATH, fname)\n",
    "    image = cv2.imread(img_path)\n",
    "    print(f\"\\nüì∑ Processing {fname}...\")\n",
    "\n",
    "    detections = model(image)[0]  # get first image prediction\n",
    "    result = {\"image\": fname, \"fields\": []}\n",
    "\n",
    "    for box in detections.boxes:\n",
    "        cls = int(box.cls.item())\n",
    "        label = model.names[cls]\n",
    "        xyxy = box.xyxy.cpu().numpy().astype(int)[0]\n",
    "\n",
    "        cropped = crop_image_with_box(image, xyxy)\n",
    "        cleaned = clean_ocr_image(cropped)\n",
    "        text = extract_text(cleaned)\n",
    "        fields = extract_fields(text)\n",
    "\n",
    "        result[\"fields\"].append({\"label\": label, \"text\": text.strip(), **fields})\n",
    "        draw_box_and_label(image, xyxy, label)\n",
    "\n",
    "    results.append(result)\n",
    "    cv2.imwrite(f\"output/annotated_{fname}\", image)\n",
    "\n",
    "print(\"\\n‚úÖ DONE. Check output/ folder.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
